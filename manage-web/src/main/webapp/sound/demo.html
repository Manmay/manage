<!DOCTYPE html>
<html>
<head>
    <title></title>

    <script src="//cdnjs.cloudflare.com/ajax/libs/annyang/1.4.0/annyang.min.js"></script>
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
    <script>
        if (annyang) {
            console.log('Found Annyang');
            // Let's define our first command. First the text we expect, and then the function it should call
            var commands = {
                'hello': function() { alert('You Said : Hello '); },
                'hi' : function() { alert('You Said : Hii '); }
            };

            annyang.debug();

            // Add our commands to annyang
            annyang.addCommands(commands);

            // Start listening. You can call this here, or attach this call to an event, button, etc.
            annyang.start();

            console.log('Started Annyang');
        }
    </script>
    <!--<script src="/js/voice-commands.min.js" type="text/javascript"></script>-->
    <!--<script type="text/javascript">-->
        <!--if ( SPEECH.isCapable() ) { // the browser supports speech recognition-->

            <!--SPEECH.onStart = function() {-->
                <!--// fires once browser recognition has started-->
                <!--console.log('on start');-->
            <!--};-->

            <!--SPEECH.onStop = function() {-->
                <!--// fires when speech is manually stopped, or on error-->
                <!--console.log('on stop');-->
            <!--};-->

            <!--SPEECH.min_confidence = .2; // the default minimum confidence you're willing to accept as a command-->

            <!--SPEECH.addVoiceCommands([-->
                <!--{-->
                    <!--command: "show help",-->
                    <!--callback: function() {-->
                        <!--// do something when the user says "show help". Maybe open a help dialog!-->
                    <!--},-->
                    <!--min_confidence: .5 // you can set a confidence level for each command individually-->
                <!--},-->
                <!--{-->
                    <!--command: /next (slide)?/,-->
                    <!--callback: function() {-->
                        <!--// this would fire when the user says "next" OR "next slide"-->
                        <!--// using a regex like that makes the voice command recognition-->
                        <!--// a bit more forgiving-->
                    <!--}-->
                <!--},-->
                <!--{-->
                    <!--command: /go.+(top|home)/, // regex to match commands more dynamically-->
                    <!--callback: function() {-->
                        <!--// the regex above would match:-->
                        <!--//  * go home-->
                        <!--//  * go to the top-->
                    <!--}-->
                <!--}-->
        <!--]);-->

        <!--SPEECH.onResult = function(transcript) {-->
            <!--// fires after commands set via addVoiceCommands are parsed.-->
            <!--// transcript is the object built by the speech recognition engine.-->
        <!--};-->

        <!--// gets things going. when speech recognition is ready,-->
        <!--// onStart will be called.-->
        <!--SPEECH.start();-->
        <!--}-->
    <!--</script>-->
</head>
<body>

<button onclick="annyang.start()">Start</button>


</body>
</html>